#+TITLE: The PAC Learning Framework

* PAC Learning
- "What can be learned efficiently? What is inherently hard to learn? How many
  examples are needed to learn successfully? Is there a general model of
  learning?"
- The answer to all of these questions (and more!) is probably approximately
  correct (PAC) learning
- PAC framework defines the class of learningable concepts in terms of thYe
  number of samples required to achieve an approximate solution and the
  time/space complexity of the learning algorithm itself

* The PAC Learning model

Some definitions and notationSome definitions and notation:
1. $\mathcal{X}$: The input space, the set of all possible examples or
   instances. For example, $\mathbb{R}^{4}$.
2. $\mathcal{Y}$: The output space, the set of all possible labels. $\mathcal{Y}
   = \{0, 1\}$ is binary classification. This is the example we will be using
   for this chapter.
3. A concept $c : \mathcal{X} \rightarrow \mathcal{Y}$, is a function that maps
   from $\mathcal{X}$ to $\mathcal{Y}$. Since we are assuming $\mathcal{Y} =
   \{0, 1\}$, we can think of $c$ as defining a subset of $\mathcal{X}$, one
   s.t. $c(x) = 1$.
4. A concept class, $\mathcal{C}$, is a set of concepts we might want to
   learn. For example, the set of all planar aligned triangles.
5. A fixed distribution, $\mathcal{D}$, from which all of our examples in
   $x \in \mathcal{X}$ will be drawn. This distribution is unknown to the
   learning algorithm.
6. A hypothesis set, $\mathcal{H}$ s.t $h : \mathcal{X} \rightarrow
   \mathcal{Y}$. These hypothesis represent the class of functions that our
   algorithm can output. They may or may not coincide with $\mathcal{C}$.

The learning problem is then defined as follows. The algorithm receives a set of
m points, $S = (x_1, \dots x_m)$, sampled according to $\mathcal{D}$. These
points are labeled according to a hidden $c \in \mathcal{C}$, s.t. $L = (c(x_1),
\dots, c(x_m))$. The task of the learning algorithm is to receive these labeled
examples and output an $h \in \mathcal{H}$.

But what do we want out of our $h$? We want something with a low generalization
error. This is the provability of $h(x)$ giving a different output than $c(x)$
given points sampled from $\mathcal{D}$. 
\begin{equation}
R(h) = \mathbb{P}_{x \sim \mathcal{D}} [h(x) \ne c(x)]  = \mathbb{E}_{x \sim \mathcal{D}} [1_{h(x) \ne c(x)}]
\end{equation}
We can always get an empirical estimate for this value with a set of samples
from $\mathcal{D}$. 
\begin{equation}
\hat{R}_S(h) = \frac{1}{m} \sum^{m}_{i = 1} 1_{h(x_i) \ne c(x_i)}
\end{equation}
Just off the bat, we know from statistics that $\hat{R}_S(h)$ tells us a good
deal about $R(h)$, depending on how large of a set we use. For one, we know that
the expectation of $\hat{R}_S(h) = R(h)$. We also know that the variance of this
estimate is $\frac{\sigma^2}{n}$, where $\sigma$ is the variance of
$\mathcal{D}$. 

Let's now fully define PAC Learning. Let $n$ be a number such that the
computational cost of representing any element $x \in \mathcal{X}$ is at most
$O(n)$. Let's say size$(c)$ is the maximum cost of a representation of $c \in
\mathcal{C}$. Let's say $h_{S}$ is the hypothesis returned by the learning
algorithm after receiving a labeled sample $S$.

We can then define a PAC-learnable concept class as a concept class
$\mathcal{C}$ such that there exists an algorithm $\mathcal{A}$ and a polynomial
function $p$ such that for any $\epsilon > 0$ and $\delta > 0$, for all
distributions $\mathcal{D}$ on $\mathcal{X}$ and for any target concept $c \in
\mathcal{C}$, the following holds for any sample size $m \ge
p(\frac{1}{\epsilon}, \frac{1}{\delta}, n, size(c))$:

\begin{equation}
\mathbb{P}_{S \sim \mathcal{D}}[R(h_S) \le \epsilon] \ge 1 - \delta
\end{equation}

In other words, the probability of the learned hypothesis $h_S$ having an error
less than $\epsilon$ is greater than $1 - \delta$. Or, $h_s$ is *probably* (with
probability $\ge 1 - \delta$) *approximately correct* (error less than
$\epsilon$). 

Things worth emphasizing:
1. This is a *distribution-free model*. We made exactly zero assumptions about
   $\mathcal{D}$. Any distribution we define over $\mathcal{X}$ is valid!
2. The train and test samples are drawn i.i.d from the same
   distribution. Without this assumption, everything would fall apart. And
   learning would generally be impossible.
3. Learning is defined against a *concept class*, not any specific concept, and
   this class is known to the algorithm. This is likely the most unrealistic assumption.

* Learning Axis-Aligned Rectangles

Consider a case where $\mathcal{X} = \mathbb{R}^2$, points in 2D space. Now,
lets say that $\mathcal{C}$ is the class of axis aligned rectangles. Each $c \in
\mathcal{C}$ will return $c(x) = 1$ if $x$ is within the rectangle. Our goal
will be to design a PAC-learning algorithm that will take as input the labeled
set of 2D points, and return a rectangle $R'$, with a low enough error compared
to actual concept defined by $R$.

We can think of the error between two rectangles in terms of the probability
weighted areas where $R'$ does not agree with $R$. The false positive region is
all of $R'$ that is not in $R$. The false negative region is all of $R$ that is
not in $R'$. 

We can define our algorithm, $\mathcal{A}$, simply to find the minimum spanning
$R$ that covers all of the positive points. By definition, this box cannot
return any false positives, since the box must by definition be contained in
$R$. So we only need to think about the false negatives. 

First, let's think about the probability mass of R. If $\mathbb{P}(R) \le
\epsilon$, then by definition our algorithm will not have an error $> \epsilon$,
since the probability of even having the ability to create a false negative is
below $\epsilon$.

Let's think about those false negatives that might happen. For each edge, we can think about the
gap between the $R$ edge and the $R'$ edge. For each edge there

There are four dimensions in which $R_S$ can fall short of $R$. For each of these
dimensions, let's imagine a region, $r_i$, in which $P(r_i) \ge
\frac{\epsilon}{4}$. If the edge of $R_S$ falls within this region, then the
total error contributed from that dimension is less then
$\frac{\epsilon}{4}$. If $R_S$ falls within none of these regions, then the total
area must be at least $\epsilon$.

We can use this event to find a lower bound on the error. The probability of
getting an error greater than $\epsilon$ is at least the probability of this
event occurring. In other words, the probability of the error being more than
epsilon is at least the probability that $R_S$ intersects with none of the
specified $r_i$ regions. Mathematically,

\begin{equation}
\mathbb{P} [ R(R_S) > \epsilon ] \le \mathbb{P} [ \cup^4_{i = 1} \{ R_S \cap r_i = \emptyset \} ]
\end{equation}

We can simplify this using a union bound. For any union of multiple events, the
total probability is bounded by the sum of the individual probabilities. In
other words,

\begin{equation}
\mathbb{P} [ \cup^4_{i = 1} \{ R_S \cap r_i = \emptyset \} ] \le \sum^4_{i = 1} \mathbb{P} [ \{ R_S \cap r_i = \emptyset \} ]
\end{equation}

So what is the probability of $\{ R_S \cap r_i \ne \emptyset \}$? Well, that is
simply the probability that none of our samples from $\mathcal{D}$ land in
$r_i$. We know that, by definition, the probability of a sample falling in $r_i$
is greater than or equal to $\frac{\epsilon}{4}$. So, conversely, the
probability of a sample not falling in $r_i$ is $1 - \frac{\epsilon}{4}$. So,
the probability of all m samples not falling in $r_i$ is,

\begin{equation}
\mathbb{P} [ \{ R_S \cap r_i = \emptyset \} ] \le (1 - \frac{\epsilon}{4})^m
\end{equation}

One last fun fact, we know that $1 - x \le \exp^{-x}$. So, from above we can
say,

\begin{equation}
(1 - \frac{\epsilon}{4})^m \le \exp(-m \epsilon / 4)
\end{equation}

We can now put this all together now and say,

\begin{aligned}
\mathbb{P} [ R(R_S) > \epsilon ] & \le \mathbb{P} [ \cup^4_{i = 1} \{ R_S \cap r_i = \emptyset \} ] \\
& \le \sum^4_{i = 1} \mathbb{P} [ \{ R_S \cap r_i = \emptyset \} ] \\
& \le \sum^4_{i = 1} (1 - \frac{\epsilon}{4})^m \\
& \le 4 (1 - \frac{\epsilon}{4})^m \\
& \le 4 \exp(-m \epsilon / 4) \\
\end{aligned}

We now have a relationship between our probability of success, the error and
$m$. If we want the probability of success


\exp(-m \epsilon / 4) \le \delta
