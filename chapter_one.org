#+TITLE: The PAC Learning Framework

* PAC Learning
- "What can be learned efficiently? What is inherently hard to learn? How many
  examples are needed to learn successfully? Is there a general model of
  learning?"
- The answer to all of these questions (and more!) is probably approximately
  correct (PAC) learning
- PAC framework defines the class of learningable concepts in terms of thYe
  number of samples required to achieve an approximate solution and the
  time/space complexity of the learning algorithm itself

* The PAC Learning model

Some definitions and notationSome definitions and notation:
1. $\mathcal{X}$: The input space, the set of all possible examples or
   instances. For example, $\mathbb{R}^{4}$.
2. $\mathcal{Y}$: The output space, the set of all possible labels. $\mathcal{Y}
   = \{0, 1\}$ is binary classification. This is the example we will be using
   for this chapter.
3. A concept $c : \mathcal{X} \rightarrow \mathcal{Y}$, is a function that maps
   from $\mathcal{X}$ to $\mathcal{Y}$. Since we are assuming $\mathcal{Y} =
   \{0, 1\}$, we can think of $c$ as defining a subset of $\mathcal{X}$, one
   s.t. $c(x) = 1$.
4. A concept class, $\mathcal{C}$, is a set of concepts we might want to
   learn. For example, the set of all planar aligned triangles.
5. A fixed distribution, $\mathcal{D}$, from which all of our examples in
   $x \in \mathcal{X}$ will be drawn. This distribution is unknown to the
   learning algorithm.
6. A hypothesis set, $\mathcal{H}$ s.t $h : \mathcal{X} \rightarrow
   \mathcal{Y}$. These hypothesis represent the class of functions that our
   algorithm can output. They may or may not coincide with $\mathcal{C}$.

The learning problem is then defined as follows. The algorithm receives a set of
m points, $S = (x_1, \dots x_m)$, sampled according to $\mathcal{D}$. These
points are labeled according to a hidden $c \in \mathcal{C}$, s.t. $L = (c(x_1),
\dots, c(x_m))$. The task of the learning algorithm is to receive these labeled
examples and output an $h \in \mathcal{H}$.

But what do we want out of our $h$? We want something with a low generalization
error. This is the provability of $h(x)$ giving a different output than $c(x)$
given points sampled from $\mathcal{D}$. 
\begin{equation}
R(h) = \mathbb{P}_{x \sim \mathcal{D}} [h(x) \ne c(x)]  = \mathbb{E}_{x \sim \mathcal{D}} [1_{h(x) \ne c(x)}]
\end{equation}
We can always get an empirical estimate for this value with a set of samples
from $\mathcal{D}$. 
\begin{equation}
\hat{R}_S(h) = \frac{1}{m} \sum^{m}_{i = 1} 1_{h(x_i) \ne c(x_i)}
\end{equation}
Just off the bat, we know from statistics that $\hat{R}_S(h)$ tells us a good
deal about $R(h)$, depending on how large of a set we use. For one, we know that
the expectation of $\hat{R}_S(h) = R(h)$. We also know that the variance of this
estimate is $\frac{\sigma^2}{n}$, where $\sigma$ is the variance of
$\mathcal{D}$. 

Let's now fully define PAC Learning. Let $n$ be a number such that the
computational cost of representing any element $x \in \mathcal{X}$ is at most
$O(n)$. Let's say size$(c)$ is the maximum cost of a representation of $c \in
\mathcal{C}$. Let's say $h_{S}$ is the hypothesis returned by the learning
algorithm after receiving a labeled sample $S$.

We can then define a PAC-learnable concept class as a concept class
$\mathcal{C}$ such that there exists an algorithm $\mathcal{A}$ and a polynomial
function $p$ such that for any $\epsilon > 0$ and $\delta > 0$, for all
distributions $\mathcal{D}$ on $\mathcal{X}$ and for any target concept $c \in
\mathcal{C}$, the following holds for any sample size $m \ge
p(\frac{1}{\epsilon}, \frac{1}{\delta}, n, size(c))$:

\begin{equation}
\mathbb{P}_{S \sim \mathcal{D}}[R(h_S) \le \epsilon] \ge 1 - \delta
\end{equation}

In other words, the probability of the learned hypothesis $h_S$ having an error
less than $\epsilon$ is greater than $1 - \delta$. Or, $h_s$ is *probably* (with
probability $\ge 1 - \delta$) *approximately correct* (error less than
$\epsilon$). 

Things worth emphasizing:
1. This is a *distribution-free model*. We made exactly zero assumptions about
   $\mathcal{D}$. Any distribution we define over $\mathcal{X}$ is valid!
2. The train and test samples are drawn i.i.d from the same
   distribution. Without this assumption, everything would fall apart. And
   learning would generally be impossible.
3. Learning is defined against a *concept class*, not any specific concept, and
   this class is known to the algorithm. This is likely the most unrealistic assumption.

* Learning Axis-Aligned Rectangles

Consider a case where $\mathcal{X} = \mathbb{R}^2$, points in 2D space. Now,
lets say that $\mathcal{C}$ is the class of axis aligned rectangles. Each $c \in
\mathcal{C}$ will return $c(x) = 1$ if $x$ is within the rectangle. Our goal
will be to design a PAC-learning algorithm that will take as input the labeled
set of 2D points, and return a rectangle $R'$, with a low enough error compared
to actual concept defined by $R$.

We can think of the error between two rectangles in terms of the probability
weighted areas 

