
#+TITLE: PAC Learning By Example In Haskell
#+OPTIONS: toc:nil author:nil timestamp:nil 

[[https://cs.nyu.edu/~mohri/mlbook/][Link to the book]]

* Probably Approximately Correct (PAC) Learning

What can be learned? Are some things harder to learn than others? 

PAC learning is a powerful framework for thinking about machine learning and all
of these questions. It also, fun fact, is the namesake for this website. The goal of this
installment is to walk through some of the basic ideas of PAC learning by
demonstration in Haskell.

This post heavily relies on the first chapter of the book "Foundations of
Machine Learning" and notes from a series of lectures given by Leslie Valiant.

** Introduction

Machine learning can be roughly described as a process of "learning" a model from
a dataset. Let's make this a little more concrete. 

We have an input space, $\mathcal{X}$. This is the underlying type that will
use to represent our data. For example, if $\mathcal{X} = \mathbb{R}^2$, then
our input or raw data is going to be two dimensional real numbers. 

We have the output space, $\mathcal{Y}$. This could be a list of classes,
(e.g. $\mathcal{Y} = \{\text{"cat"},  \text{"dog"} \}$), or an estimated value for
a regression problem (e.g. $\mathcal{Y} = \mathbb{R}$). For this post,
we will focus on binary classification problems, $\mathcal{Y} = \{ 0, 1 \}$,
which we will represent as booleans.

What we want to learn is a function, or concept, that maps from the input space to
the output space. Mathematically, 
\begin{equation}
c: \mathcal{X} \rightarrow \mathcal{Y}
\end{equation}

In haskell, we can make a type synonym for clarity,  
#+BEGIN_SRC haskell
type Concept x y = x -> y
#+END_SRC

In order to learn this function, will have some dataset, $S = ((x_1, y_1),
\dots, (x_m, y_m))$. Each $x_i \sim \mathcal{D}$, where $\mathcal{D}$ is some
distribution. 

In haskell, we will be using the =Control.Monad.Random= module for handling
random numbers. Again, we can use a type alias to clean things up a bit. We will
have our distribution, 
#+BEGIN_SRC haskell
type Distribution x = Rand StdGen x
#+END_SRC
From which we can i.i.d sample a list of data points,
#+BEGIN_SRC haskell
sampleFrom :: Int -> Distribution x -> Distribution [x]                                         
sampleFrom m dist = sequence (replicate m dist)     
#+END_SRC
This function takes an integer $m$ and a distribution and returns m samples from
that distribution. Given a list of samples $\in \mathcal{X}$, we can generate a
dataset by simply applying the concept to all of the generated points.
#+BEGIN_SRC haskell
labelData :: Concept x y -> [x] -> [(x, y)]                                                     
labelData concept dataList = map (\x -> (x, concept x)) dataList
#+END_SRC
In other words, given a concept $c$, a list of $m$ samples $x_0, x_1, \dots,
x_m$ s.t. $x \in \mathcal{X}$, we can construct a dataset $S$ as $(x_0, c(x_0)),
(x_1, c(x_1), \dots (x_m, c(x_m))$.

Let's say we have another hypothesis concept, $h$, defined over the same input
and output space. More specifically, let's say that $h$ is the result of some
learning process over data generated by $c$. How can we evaluate how well it fit
the data? Well this $\mathcal{Y}$ is a binary label, we can compute its error
with respect $h$ by measuring the probability that $h$ and $c$ disagree over
$\mathcal{D}$,
\begin{equation}
R(h) = \mathbb{P}_{x \sim \mathcal{D}} [h(x) \ne c(x)]  = \mathbb{E}_{x \sim \mathcal{D}} [1_{h(x) \ne c(x)}]
\end{equation}
$R(h) = 1$ would mean $h$ and $c$ never agree while $R(h) = 0$ would mean that
$h$ and $c$ always agree. Note, that this doesn't mean that $h$ and $c$ are
identical, or that $h(x) = c(x) \forall x \in \mathcal{X}$, just that $h$ and
$c$ give identical labels to data generated by $\mathcal{D}$.

Computing $R(h)$ analytically is difficult, but it is easy to swap it out for an
empirical estimate,
\begin{equation}
\hat{R}_S(h) = \frac{1}{m} \sum^{m}_{i = 1} 1_{h(x_i) \ne c(x_i)}
\end{equation}
In haskell, we can perform this computation over a labeled set of data. First,
given a labeled point $(x, y)$, we can check if $c$ outputs the correct label as,
#+BEGIN_SRC haskell
isIncorrect :: (Eq y) => Concept x y -> (x, y) -> Bool
isIncorrect c (x, y) = (c x) /= y
#+END_SRC
Then, we can apply this over an entire dataset and compute the portion of
incorrectly labeled examples,
#+BEGIN_SRC haskell
errorOf :: (Eq y) => Concept x y -> [(x, y)] -> Float
errorOf concept dataList = 
    let evalList = map (\x -> if isIncorrect concept x then 1.0 else 0.0) dataList
        total = (fromIntegral . length) evalList
     in (sum evalList) / total
#+END_SRC
By sampling a large enough set of labeled samples, we can use this function to
get an estimate of $R(h)$. 

** Probably Approximately Correct

Let's now fully define PAC Learning. Let $n$ be a number such that the
computational cost of representing any element $x \in \mathcal{X}$ is at most
$O(n)$. Let's say size$(c)$ is the maximum cost of a representation of $c \in
\mathcal{C}$. Let's say $h_{S}$ is the hypothesis returned by the learning
algorithm after receiving a labeled sample $S$.

We can then define a PAC-learnable concept class as a concept class
$\mathcal{C}$ such that there exists an algorithm $\mathcal{A}$ and a polynomial
function $p$ such that for any $\epsilon > 0$ and $\delta > 0$, for all
distributions $\mathcal{D}$ on $\mathcal{X}$ and for any target concept $c \in
\mathcal{C}$, the following holds for any sample size $m \ge
p(\frac{1}{\epsilon}, \frac{1}{\delta}, n, size(c))$:

\begin{equation}
\mathbb{P}_{S \sim \mathcal{D}}[R(h_S) \le \epsilon] \ge 1 - \delta
\end{equation}

In other words, the probability of the learned hypothesis $h_S$ having an error
less than $\epsilon$ is greater than $1 - \delta$. Or, $h_S$ is *probably* (with
probability $\ge 1 - \delta$) *approximately correct* (error less than
$\epsilon$). 

Things worth emphasizing:
1. This is a *distribution-free model*. We made exactly zero assumptions about
   $\mathcal{D}$. Any distribution we define over $\mathcal{X}$ is valid!
2. The train and test samples are drawn i.i.d from the same
   distribution. Without this assumption, everything would fall apart. And
   learning would generally be impossible.
3. Learning is defined against a *concept class*, not any specific concept, and
   this class is known to the algorithm. This is likely the most unrealistic assumption.

In haskell, we can then represent the PAC learning setup as a tuple containing:
1. The distribution we will use to be sample points from $\mathcal{X}$. 
2. A function to sample a hidden concept $c$
3. A learning algorithm that takes a dataset $S$ and returns a concept $h_S$
4. The desired error, $\epsilon$

In other words,
#+BEGIN_SRC haskell
type PACTuple x y = (Distribution x, Distribution (Concept x y), [(x, y)] -> Concept x y, Float)
#+END_SRC 
Given one of these tuples and a dataset size $m$, we can evaluate whether or not
the learning algorithm succeeds as,
#+BEGIN_SRC haskell
pacEvaluate :: PACTuple x Bool -> Int -> IO Bool
pacEvaluate (distribution, generateConcept, learnFn, epsilon) m = do
  -- Sample a hidden concept, c
  hiddenConcept <- evalRandIO (generateConcept)
  -- Create a set of training points, S
  trainPoints <- evalRandIO (sampleFrom m distribution)
  -- Create an evaluation set to estimate R(h_S)
  testPoints <- evalRandIO (sampleFrom 10000 distribution)
  
  let labeledTrainPoints = labelData hiddenConcept trainPoins
      labeledTestPoints = labelData hiddenConcept testPoints
      -- Learn h_S 
      hypothesis = learnFn labeledTrainPoints
      -- Estimate its error
      measuredError = errorOf hypothesis labeledTestPoints
      -- Check whether this error is less than the desired bound
      success = measuredError <= epsilon

  return success
#+END_SRC 
We can then empirically estimate the $\delta$ for this algorithm by running the
above process multiple times and computing the probability of success,
#+BEGIN_SRC haskell
estimateDelta :: PACTuple x Bool -> Int -> Int -> IO Float
estimateDelta pac m n = do
  val <- sequence [pacEvaluate pac m | x <- [1..n]]
  let failures = map (\x -> if x then 0.0 else 1.0) val
  let mean = (sum failures) / (fromIntegral n)
  return mean
#+END_SRC 

** PAC Learning Intervals
Let's work through an example on a simple concept class, intervals. Our input
space is going to be one dimensional real numbers, $\mathcal{X} =
\mathbb{R}$, and our output space will still be binary. An interval will have a
lower and upper bound, and it will only return $c(x) = 1$ if $x$ is within these
bounds. We can represent this kind of function in haskell as,
#+BEGIN_SRC haskell
isInInterval :: Float -> Float -> Float -> Bool
isInInterval lower upper val = (val >= lower) && (val <= upper)
#+END_SRC 
We can randomly construct an interval by sampling a lower and upper bound,
#+BEGIN_SRC haskell
randomBounds :: Distribution (Float, Float)
randomBounds = do
    valOne <- getRandom
    valTwo <- getRandom
    if valOne < valTwo
        then return (valOne, valTwo)
        else return (valTwo, valOne)
#+END_SRC 
And then applying our =isInInterval= function,
#+BEGIN_SRC haskell
randomInterval :: Distribution (Float -> Bool) 
randomInterval = do
    (lower, upper) <- randomBounds
    return (isInInterval lower upper)
#+END_SRC 
Our goal is to develop a PAC-learning algorithm for this concept class. 

Let's say we have a dataset $S$ of labeled points by some hidden interval
$c$. If we construct a new $h$, there are two types of ways it can be wrong:
1. A false positive: $h(x) = 1, c(x) = 0$ 
2. A false negative: $h(x) = 0, c(x) = 1$
An obvious algorithm would be to take the points in $S$, find the maximum point
such that $c(x) = 1$ and the minimum point such that $c(x) = 1$ and use those as
the bounds of the interval. We can implement this algorithm by composing a
function that only returns the positive examples in our training set, and one
that then uses those positive points to construct the interval,
#+BEGIN_SRC haskell
getPositivePoints :: [(x, Bool)] -> [x]
getPositivePoints = (map fst) . (filter snd)

pointsToInterval :: [Float] -> Concept Float Bool
pointsToInterval [] = \x -> False 
pointsToInterval positive_points = 
        isInInterval (minimum positive_points) (maximum positive_points)

learnInterval :: [(Float, Bool)] -> Concept Float Bool
learnInterval = (pointsToInterval . getPositivePoints)
#+END_SRC

This intuitive algorithm also has the nice property
that we do not need to think about the potential for false positives. If we
think about these two functions as forming sets of $\mathcal{X}$ where $f(x) =
1$, then we know that $h_S \in c$. 

In other words, $h_S$ will always define a slightly smaller interval than
$c$. For each concept $f$, lets say the parameters of their intervals are $(l_f,
u_f)$ where $l_f$ corresponds to the lower bound of $f$ and $u_f$ corresponds to
the upper bound of $f$. The error between $h$ and $c$ is the probability that a
point falls in the region between the outer bound of $c$ and the inner bound of $h$,
\begin{equation}
R(h) = \mathbb{P}_{x \sim \mathcal{D}} [ x \in (l_c, l_h) \text{ or } x \in (u_h, u_c)]
\end{equation}

Let's imagine two buffer regions, $r_l$ and $r_u$. $r_l$ is the buffer on the
lower region such that the probability of a point landing in $r_l$ is
$\frac{\epsilon}{2}$. In other words, $r_l = (l_c, z)$ where $z$ is whatever
value it takes so that
\begin{equation}
\mathbb{P}_{x \sim \mathcal{D}} [ x \in r_l ] = \frac{\epsilon}{2} 
\end{equation}
$r_u$ is defined similarly, but for the upper region. Note that this region is
independent of our $h$. 

Let's say that $h_l \in r_l$ and $h_u \in r_u$. We then know that, 
\begin{align}
R(h) &= \mathbb{P}_{x \sim \mathcal{D}} [ x \in (l_c, l_h) \text{ or } x \in (u_h, u_c)] \\
     &= \mathbb{P}_{x \sim \mathcal{D}} [ x \in (l_c, l_h) ] + \mathbb{P}_{x \sim \mathcal{D}} [x \in (u_h, u_c)] \\
     & \le \mathbb{P}_{x \sim \mathcal{D}} [ x \in r_l ] + \mathbb{P}_{x \sim \mathcal{D}} [x \in r_u] \\
     & \le \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
     & \le \epsilon \\
\end{align}
In other words, if both of the upper and lower bounds of our learned interval
$h$ fall in the buffer regions, we know that the error is less than
$\epsilon$. What is the probability of this happening? 

We know that by definition for each buffer region, 
\begin{equation}
\mathbb{P}_{x \sim \mathcal{D}} [ x \in r ] = \frac{\epsilon}{2}
\end{equation}
That means that for every sample from $\mathcal{D}$, the probability that the
point *doesn't* fall in $r$ is $1 - \frac{\epsilon}{2}$. So the probability that
all of our $m$ points don't fall in the region is,
\begin{equation}
\mathbb{P}_{x \sim \mathcal{D}} [ (h_S \not \in r) ] = (1 - \frac{\epsilon}{2})^m
\end{equation}
What is the probability that both don't receive any points? Here, we can greatly
simplify the analysis by using a union bound. For any two events $A$ and $B$,
the probability of both $A$ and $B$ occurring is less than the sum of the
probabilities of $A$ and $B$ individually. Or,
\begin{equation}
P(A \cup B) \le P(A) + P(B)
\end{equation}
Another fact that will prove useful is that $1 - x \le \exp(-x)$ for all $x \in
\mathbb{R}$. We can then just say that,
\begin{align}
\mathbb{P}_{x \sim \mathcal{D}} [ (x \not \in r_l) \cup (x \not \in r_u) ]  & \le 
\mathbb{P}_{x \sim \mathcal{D}} [ (x \not \in r_l) ] + \mathbb{P}_{x \sim \mathcal{D}} [ (x \not \in r_u) ]  \\
 & \le (1 - \frac{\epsilon}{2})^m + (1 - \frac{\epsilon}{2})^m \\
 & \le 2 (1 - \frac{\epsilon}{2})^m \\
 & \le 2 \exp( -m \epsilon / 2) \\
\end{align}
This means that the probability that our learning algorithm will fail to produce
a hypothesis with an error $\le \epsilon$ is $\le 2 \exp(-m \epsilon / 2)$. Or,
in terms of our $\delta$,
\begin{equation}
 \delta \ge 2 \exp( -m \epsilon / 2) \\
\end{equation}

Let's verify this bound by comparing with some empirical data. We can estimate
the delta for a series of values of $m$, and then plot that data. First, we need
a function to get this data.
#+BEGIN_SRC haskell
outputData :: PACTuple a Bool -> Int -> Int -> Int -> IO ()
outputData pactuple n step max = do
    -- Create the range of potential m values, the size of the training set
    let mVals = [0,step..max]
    -- For each m, estimate the delta with n samples
    val <- sequence $ [ estimateDelta pactuple m n | m <- mVals]
    -- Format the string for output
    let both = zip val mVals
        fmtString currentString (val, m) = 
                currentString ++ (show m) ++ " " ++ (show val) ++ "\n"
        outputString = foldl fmtString "" both
    putStrLn outputString
#+END_SRC
We can then create a =PACTuple= for the interval and generate this data,
#+BEGIN_SRC haskell
let intervalPAC = (getRandom, randomInterval, learnInterval, 0.01) :: PACTuple Float Bool
outputData intervalPAC 300 25 600
#+END_SRC
Plotting this data, we can see that it does in fact follow the bound.

[[./plots/interval.png]]

It's worth taking a moment to reflect on what we just were able to prove. We
were able to derive a probabilistic bound on the error based on the dataset size
alone. Given a $m$ and $\epsilon$, you can predict what the probability of
success of reaching that $\epsilon$ is entirely irrespective of the underlying
data distribution. Conversely, given an $\epsilon$ and a $\delta$, you can
determine the $m$ you need to guarantee you'll satisfy those constraints. 

** Boxes

We can generalize the above case to higher dimensions by taking the union of
intervals over different dimensions. For example, we can change from an interval
to a axis-aligned box in two dimensions by taking the union of two intervals

#+BEGIN_SRC haskell
type Point = (Float, Float)

boxInterval :: Concept Float Bool -> Concept Float Bool -> Concept Point Bool
boxInterval xInterval yInterval = \(x,y) -> ((xInterval x) && (yInterval y))
#+END_SRC 

Our input space here is now $\mathbb{R}^2$, which we are referring to as the
type =Point=. Our box is defined as an interval in the x dimension and an interval
in the y dimension.  

We can again randomly sample points and boxes in a very similar method to before,
#+BEGIN_SRC haskell
randomBox :: Distribution (Point -> Bool)
randomBox = do 
    xInterval <- randomInterval
    yInterval <- randomInterval
    return (boxInterval xInterval yInterval)

randomPoint :: Distribution Point
randomPoint = do
    valOne <- getRandom
    valTwo <- getRandom
    return (valOne, valTwo)
#+END_SRC
And our learning function will require simply splitting up the learning problem
into the two dimensions,
#+BEGIN_SRC haskell
pointsToBox :: [Point] -> (Point -> Bool)
pointsToBox [] = \x -> False
pointsToBox positive_points = 
       let xInterval = pointsToInterval (map fst positive_points)
            yInterval = pointsToInterval (map snd positive_points)
        in boxInterval xInterval yInterval

learnBox :: [(Point, Bool)] -> Concept Point Bool
learnBox = (pointsToBox . getPositivePoints)
#+END_SRC
We can generalize the proof above to depend on the dimensions of the
intervals.

\begin{equation}
\delta \ge 2d \exp( -m \epsilon / (2d))
\end{equation}

Before, we only cared about the one dimensional line ($d = 1$). Now,
we have a box with $d = 2$. We can again generate some empirical data and
again confirm that this bound holds. 

#+BEGIN_SRC haskell
let boxPAC = (randomPoint, randomBox, learnBox, 0.01) :: PACTuple Point Bool
outputData boxPAC 300 25 1000
#+END_SRC
Which we can plot again,

[[./plots/box.png]]

More importantly, this framework allows us to analyze how the dimension effects
problem difficulty. We can rearrange the above expression to get,

\begin{equation}
m \ge \frac{2d}{\epsilon} \log \frac{2d}{\delta}
\end{equation}

This means that the total sample size required to reach a constant $\epsilon$ and
$\delta$ is growing $O(d \log d)$.

** Boolean Conjunctions
The previous proofs relied on some geometric properties of intervals. It is
worth demonstrating that we can provide similar proofs for increasingly complex
kinds of functions. For example, consider boolean conjunctions over $k$ literals
of the form,

\begin{equation}
x_1 \land x_3 \land \not x_4
\end{equation}

Each literal is either:
1. Unused: the value of this literal is ignored
2. Used: the value of this literal is part of the conjunction
3. Negated: the negation of this literal is part of the conjunction

We can implement 
#+BEGIN_SRC haskell
type BoolVector = [Bool]
type LiteralVector = [Literal]

data Literal = Used | Negated | Unused
             deriving (Eq, Show)

evalLiteral :: Literal -> Bool -> Bool
evalLiteral Unused _      = True
evalLiteral Negated True  = False
evalLiteral Negated False = True
evalLiteral Used x        = x

satisfiesLiteral :: LiteralVector -> BoolVector -> Bool
satisfiesLiteral [] [] = True
satisfiesLiteral l [] = False
satisfiesLiteral [] b = False
satisfiesLiteral (l:otherLiterals) (b:otherBools) = (evalLiteral l b) && satisfiesLiteral otherLiterals otherBools
#+END_SRC

Generating random literals is a little more complicated, first we can write a
function that randomly generates literals

#+BEGIN_SRC haskell
floatToLiterval :: Float -> Literal
floatToLiterval val 
  | val <= 0.1 = Used
  | val <= 0.2 = Negated
  | otherwise = Unused

randomLiteral :: Distribution Literal
randomLiteral = do
    val <- getRandom
    return (floatToLiterval val)
#+END_SRC
The numbers selected in =floatToLiteral= are arbitrary. We can then use this to 
#+BEGIN_SRC haskell
randomLiteralExpression :: Int -> Distribution (Concept BoolVector Bool)
randomLiteralExpression n = do
	  random_val <- (sampleFrom n randomLiteral) 
	  return (satisfiesLiteral random_val)
#+END_SRC
We can use the built in =getRandom= to sample booleans for the =BoolVector=.
#+BEGIN_SRC haskell
randomBoolVector :: Int -> Distribution BoolVector
randomBoolVector n = sampleFrom n getRandom
#+END_SRC
Now, we need our learning function. 
#+BEGIN_SRC haskell
updateLiteral :: Literal -> Bool -> Literal
updateLiteral Used True = Used
updateLiteral Used False = Negated
updateLiteral Negated True = Unused
updateLiteral Negated False = Negated
updateLiteral Unused _ = Unused
#+END_SRC
#+BEGIN_SRC haskell
updateLiteralVector :: BoolVector -> LiteralVector -> LiteralVector
updateLiteralVector [] [] = []
updateLiteralVector l [] = []
updateLiteralVector [] b = []
updateLiteralVector (b:otherBools) (l:otherLiterals) = (updateLiteral l b):(updateLiteralVector otherBools otherLiterals)
#+END_SRC
#+BEGIN_SRC haskell
pointsToBoolVector :: [BoolVector] -> Concept BoolVector Bool
pointsToBoolVector dataList = let
            newAssign = foldr (updateLiteralVector) (repeat Used) dataList
         in (satisfiesLiteral newAssign)

learnLiteralExpression :: [(BoolVector, Bool)] -> Concept BoolVector Bool
learnLiteralExpression = (pointsToBoolVector . getPositivePoints)
#+END_SRC

[[./plots/bool.png]]
